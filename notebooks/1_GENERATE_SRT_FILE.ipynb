{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffc8a3a7-200e-4599-81f4-e6209a7707e4",
   "metadata": {},
   "source": [
    "# ASR & subtitles generation\n",
    "\n",
    "### *How to generate SRT file?*\n",
    "\n",
    "- Get transcription from **ASR** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdae06de-ddff-4534-b454-fff1ff158c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "dotenv_path = Path('/workspace/.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "# access the environment variables from the .env file\n",
    "asr_endpoint_url = os.environ.get('ASR_EN_US_ENDPOINT')\n",
    "ai_endpoint_token = os.environ.get('OVH_AI_ENDPOINTS_ACCESS_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fac52e-d1fd-40ae-b64c-d21349603de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import riva.client\n",
    "\n",
    "# ASR function\n",
    "def asr_transcription(source_lang, audio_input):\n",
    "\n",
    "    # connect with riva asr server\n",
    "    asr_service = riva.client.ASRService(\n",
    "                    riva.client.Auth(\n",
    "                        uri=asr_endpoint_url,\n",
    "                        use_ssl=True, \n",
    "                        metadata_args=[[\"authorization\", f\"bearer {ai_endpoint_token}\"]]   \n",
    "                    )\n",
    "                )\n",
    "\n",
    "    # set up config\n",
    "    asr_config = riva.client.RecognitionConfig(\n",
    "        language_code=source_lang,\n",
    "        max_alternatives=1,\n",
    "        enable_automatic_punctuation=True,\n",
    "        enable_word_time_offsets=True,\n",
    "        audio_channel_count = 1,\n",
    "    )\n",
    "    \n",
    "    # open and read audio file\n",
    "    with open(audio_input, 'rb') as fh:\n",
    "        audio = fh.read()\n",
    "    \n",
    "    riva.client.add_audio_file_specs_to_config(asr_config, audio)\n",
    "    riva.client.add_word_boosting_to_config(asr_config, [\"Ovh\", \"datacenter\", \"cloud\"], 20.0)\n",
    "\n",
    "    # return response\n",
    "    resp = asr_service.offline_recognize(audio, asr_config)\n",
    "    output_asr = []\n",
    "    \n",
    "    # extract sentence information\n",
    "    for s in range(len(resp.results)):\n",
    "\n",
    "        # define output lists\n",
    "        output = resp.results[s].alternatives[0]\n",
    "        output_sentence = []\n",
    "        \n",
    "        sentence = output.transcript\n",
    "        output_sentence.append(sentence)\n",
    "        \n",
    "        for w in range(len(output.words)):\n",
    "            start_sentence = output.words[0].start_time\n",
    "            end_sentence = output.words[w].end_time\n",
    "        \n",
    "        # add start time and stop time of the sentence\n",
    "        output_sentence.append(start_sentence)\n",
    "        output_sentence.append(end_sentence)\n",
    "       \n",
    "        # final asr transcription and time sequences\n",
    "        output_asr.append(output_sentence)\n",
    "        \n",
    "    # return response\n",
    "    return output_asr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e53834-fa41-4874-9e79-1e804603ab4b",
   "metadata": {},
   "source": [
    "- Convert ms into timecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4171ea13-36e9-4daa-bce0-f3ead8d2e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ms into timecode\n",
    "def ms_to_timecode(x):\n",
    "     \n",
    "    hour, x = divmod(x, 3600000)\n",
    "    minute, x = divmod(x, 60000)\n",
    "    second, x = divmod(x, 1000)\n",
    "    millisecond, x = divmod(x, 1)\n",
    "\n",
    "    return '%.2d:%.2d:%.2d,%.3d' % (hour, minute, second, millisecond)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c26cf6-6d3b-474e-9257-276ec17d53fb",
   "metadata": {},
   "source": [
    "- Create SRT file for video subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea2658-5ac2-4c7d-863b-bec7b35fe3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SRT file with subtitles\n",
    "def generate_str_file(output_asr):\n",
    "    \n",
    "    lines = []\n",
    "    for t in range(len(output_asr)):\n",
    "        lines.append(\"%d\" % t)\n",
    "        lines.append(\n",
    "            \"%s --> %s\" %\n",
    "            (\n",
    "                ms_to_timecode(output_asr[t][1]),\n",
    "                ms_to_timecode(output_asr[t][2])\n",
    "            )\n",
    "        )\n",
    "        lines.append(output_asr[t][0])\n",
    "        lines.append('')\n",
    "    \n",
    "    return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3fa0d3-d5ef-45a2-ab94-2ebb47bef5a8",
   "metadata": {},
   "source": [
    "- Play audio sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b739a4-5037-41bd-9322-9e4fb1d467fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "audio_input = \"audio_ovhcloud_en_1.wav\"\n",
    "Audio(f\"/workspace/ai-multimedia-translator/audio_samples/{audio_input}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5a3dd3-6446-433e-b047-3d399af5bf86",
   "metadata": {},
   "source": [
    "- Get results from **RIVA ASR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac449385-c077-4eb9-92b8-f6f28a15ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio transcription\n",
    "output_asr = asr_transcription(\"en-US\", f\"/workspace/ai-multimedia-translator/audio_samples/{audio_input}\")\n",
    "print(\"Transcription output - RIVA ASR:\\n\\n\", output_asr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900735d6-9833-46e2-9de3-98dbb60101e1",
   "metadata": {},
   "source": [
    "- Generate **SRT file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787fffa-e2cb-41e8-a462-0e02a05655ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtitles generation\n",
    "with open(f\"/workspace/ai-multimedia-translator/outputs/subtitles_{audio_input[:-4]}.srt\", 'w') as f:\n",
    "    f.write(generate_str_file(output_asr))\n",
    "    print(\"Generated subtitles - SRT file:\\n\\n\", generate_str_file(output_asr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
