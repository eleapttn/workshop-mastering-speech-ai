{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51ce55c8-d252-4736-9eee-713baa365531",
   "metadata": {},
   "source": [
    "# Getting started with Speech AI\n",
    "\n",
    "![ASR](./images/asr_diarization_tutorial.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbab8103-e243-4f93-9f24-8797ccb0b58b",
   "metadata": {},
   "source": [
    "By the end of this Getting Started notebook, you will be able to use Automatic Speech Recognition (ASR), Neural Machine Translation (NMT) and Text-to-Speech (TTS) APIs in your projects, opening up a wide range of possibilities for Speech AI applications.\n",
    "\n",
    "Happy learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df26fab-8732-4d02-9d0e-392e06d1fa35",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e04784d-1ff8-4130-843c-213ce8f8c6ef",
   "metadata": {},
   "source": [
    "### 1 - Making API Requests to Speech AI Models\n",
    "\n",
    "‚û°Ô∏è Before continuing, please consult the **[00-making-http-request.MD](https://github.com/eleapttn/workshop-mastering-speech-ai/blob/main/docs/00-making-http-request.MD)** documentation to discover how to make HTTP API calls to the AI Endpoints models using Python.\n",
    "\n",
    "This will be essential for interacting with the different AI models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce523e5d-0173-45ca-8525-34aaab747e10",
   "metadata": {},
   "source": [
    "### 2 - ASR Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdeb6a8-5fd4-4ee5-be16-21e8278168d1",
   "metadata": {},
   "source": [
    "Let's start with Automatic Speech Recognition model.\n",
    "\n",
    "üéØ Your task is to **send an audio file as input and receive a text transcription**. \n",
    "\n",
    "To do that, you will have to:\n",
    "\n",
    "- Play the audio file, so that you can see what is being said\n",
    "- Determine the `ASR` model you want to work with among the ones available on [AI Endpoints](https://endpoints.ai.cloud.ovh.net/)\n",
    "- Get its endpoint `URL`\n",
    "- Set up the necessary request headers\n",
    "- Provide the input data expected by the `ASR` model.\n",
    "- Send your request\n",
    "- Print the request answer and analyse the audio transcription !\n",
    "\n",
    "**‚û°Ô∏è You can find all the necessary information, such as the endpoint URL, format of expected input data, and code examples, in the [01-ASR.MD](https://github.com/eleapttn/workshop-mastering-speech-ai/blob/main/docs/01-ASR.MD) documentation file.**\n",
    "\n",
    "üí° *ASR Solution is provided in the [0_SPEECH_AI_BASICS_SOLUTION.ipynb](https://github.com/eleapttn/workshop-mastering-speech-ai/blob/main/notebooks/solutions/0_SPEECH_AI_BASICS_SOLUTION.ipynb) notebook. But try to tackle the task on your own and ask questions before checking the solution!*\n",
    "\n",
    "‚¨áÔ∏è *You can write the code in the cell below.* ‚¨áÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce29e238-d147-4a43-8e5c-553bbede2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To execute code cell, select the cell and then click the ‚ñ∂Ô∏è button in the menu above the notebook. You can also select the cell and execute `SHIFT + ENTER`.\n",
    "\n",
    "# Some audio files are provided in the /workspace/workshop-mastering-speech-ai/samples/audio_samples/ directory\n",
    "\n",
    "# Write the code to play one of these audio samples, before transcribing it (refer to documentation provided above)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc84a99-7a9b-4267-9915-0950149f79e1",
   "metadata": {},
   "source": [
    "Now that you know the audio file content, send this audio file to the ASR model to transcribe it, by making an API request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6939e9-efc0-4952-afe7-d80f2f9dc8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To execute code cell, select the cell and then click the ‚ñ∂Ô∏è button in the menu above the notebook. You can also select the cell and execute `SHIFT + ENTER`.\n",
    "\n",
    "# Then, send this audio file to the ASR model by making an API request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b190ed9-f478-483c-a2eb-cca9c111c207",
   "metadata": {},
   "source": [
    "### 3 - NMT Pipeline\n",
    "\n",
    "Now that you have successfully completed the `ASR` task, let's move on to the Neural Machine Translation model. \n",
    "\n",
    "üéØ Your task is to **translate a given text from one language to another**.\n",
    "\n",
    "Remember that you'll need to: \n",
    "\n",
    "- Determine the `NMT` model you want to work with among the ones available on [AI Endpoints](https://endpoints.ai.cloud.ovh.net/)\n",
    "- Get its endpoint `URL`\n",
    "- Set up the necessary request headers\n",
    "- Adjust the `JSON` request data to suit the newly chosen `NMT` model\n",
    "- Send your request\n",
    "- Print the response and analyze the translated text!\n",
    "\n",
    "**‚û°Ô∏è You can find all the necessary information, such as the NMT endpoint URL, format of expected input data (we are not sending an audio file anymore), and code examples, in the [02-NMT.MD](https://github.com/eleapttn/workshop-mastering-speech-ai/blob/main/docs/02-NMT.MD) documentation file.**\n",
    "\n",
    "üí° *NMT Solution is provided in the [0_SPEECH_AI_BASICS_SOLUTION.ipynb](https://github.com/eleapttn/workshop-mastering-speech-ai/blob/main/notebooks/solutions/0_SPEECH_AI_BASICS_SOLUTION.ipynb) notebook. Feel free to try the task on your own and ask questions before checking the solution.*\n",
    "\n",
    "‚¨áÔ∏è *You can code that in the cell below.* ‚¨áÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caff3205-987b-466e-8327-87cae59b9203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a text example that you can try to translate from English to another language:\n",
    "input_text = \"Devoxx Belgium is an annual conference for software developers and IT professionals. Held in Antwerp, Belgium, it is one of the largest and most well-known conferences in Europe, attracting thousands of attendees from around the world.\"\n",
    "\n",
    "# To execute code cell, select the cell and then click the ‚ñ∂Ô∏è button in the menu above the notebook. You can also select the cell and execute `SHIFT + ENTER`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e2c23d-ae87-4d0f-8a8c-a5e5d09c5a56",
   "metadata": {},
   "source": [
    "### 4 - TTS Pipeline\n",
    "\n",
    "Great job with the NMT model! \n",
    "\n",
    "üéØ Let's explore the Text-to-Speech model now. Your goal is to **convert text to human-like speech**. The process is similar to what you have done for the `ASR` and `NMT` sections, but be aware that the `accept` headers will be different this time, as we want to generate an audio file, not a text.\n",
    "\n",
    "**‚û°Ô∏è You can find all the necessary information, such as the endpoint URL, format of expected input data, and code examples, in the [03-TTS.MD](https://github.com/eleapttn/workshop-mastering-speech-ai/blob/main/docs/03-TTS.MD) documentation file.**\n",
    "\n",
    "üí° *TTS Solution is provided in the [0_SPEECH_AI_BASICS_SOLUTION.ipynb](https://github.com/eleapttn/workshop-mastering-speech-ai/blob/main/notebooks/solutions/0_SPEECH_AI_BASICS_SOLUTION.ipynb) notebook. Feel free to try the task on your own and ask questions before checking the solution.*\n",
    "\n",
    "‚¨áÔ∏è *You can code that in the cell below.* ‚¨áÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92eaa02-b7e3-4b6e-b497-c5aab1fd850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n",
    "# To execute code cell, select the cell and then click the ‚ñ∂Ô∏è button in the menu above the notebook. You can also select the cell and execute `SHIFT + ENTER`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e75e85-4a81-4503-9476-d28aea223acd",
   "metadata": {},
   "source": [
    "Once you've got the model response, read your generated audio file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26864282-f04e-4a7b-9c5b-e5cc835bad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the generated audio file here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439f9bd1-48f4-463d-b7df-af9e2a2e9efa",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Congratulations on completing this introduction to Speech AI models and AI APIs!\n",
    "\n",
    "You have successfully:\n",
    "\n",
    "- Discovered the `ASR`, `NMT`, and `TTS` models.\n",
    "- Learned how to work with `APIs` and send `HTTP` requests.\n",
    "- Provided correct input data, and used right header settings to achieve the desired output.\n",
    "\n",
    "Now, you are ready to move on to another notebook where you will put your new skills into practice with more advanced Speech AI tasks, such as subtitle generation, voice dubbling and other exciting speech AI features.\n",
    "\n",
    "The `/notebooks/1_GENERATE_SRT_FILE.ipynb` notebook is waiting for you !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
